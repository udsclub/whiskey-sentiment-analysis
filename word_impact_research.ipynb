{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"models/lstm_word2vec\"\n",
    "TEST_DATASET = \"data/test_imdb.csv\"\n",
    "\n",
    "TOKENIZER_NAME = \"models/lstm_word2vec_tokenizer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import pickle\n",
    "numpy.random.seed(42)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swith on full text mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(TEST_DATASET, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "negatives = {\n",
    "    \"didn't\": \"didn_`_t\",\n",
    "    \"couldn't\": \"couldn_`_t\",\n",
    "    \"don't\": \"don_`_t\",\n",
    "    \"wouldn't\": \"wouldn_`_t\",\n",
    "    \"doesn't\": \"doesn_`_t\",\n",
    "    \"wasn't\": \"wasn_`_t\",\n",
    "    \"weren't\": \"weren_`_t\",\n",
    "    \"shouldn't\":\"shouldn_`_t\",\n",
    "    \"isn't\": \"isn_`_t\",\n",
    "    \"aren't\": \"aren_`_t\",\n",
    "}\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('<br />', ' ')\n",
    "    text = ' '.join(tweet_tokenizer.tokenize(text))\n",
    "    for k, v in negatives.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['prep_text'] = test_data['text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. String -> Int vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #load tokenizer\n",
    "pkl_file = open(TOKENIZER_NAME, 'rb')\n",
    "tokenizer = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(test_data['prep_text'])\n",
    "\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   11,     6,    87, ...,    55,    82,    17],\n",
       "       [10361,   182,   175, ...,     4,     1,   320],\n",
       "       [ 1375,     4,   492, ...,   149,   336,   556],\n",
       "       ..., \n",
       "       [   44,    21,   201, ...,    13,   417,  5907],\n",
       "       [  788, 19456,  4878, ...,     1,  6620,   181],\n",
       "       [   15,    64,  3913, ...,   957,     4,  2144]], dtype=int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 70)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   11,     6,    87, ...,    55,    82,    17],\n",
       "       [10361,   182,   175, ...,     4,     1,   320],\n",
       "       [ 1375,     4,   492, ...,   149,   336,   556],\n",
       "       ..., \n",
       "       [   11,     6,  1561, ...,     3,  1785,  4416],\n",
       "       [   38,     2,  4315, ...,    11,   338,   177],\n",
       "       [ 1825,    19,    96, ...,     3,     5,  1507]], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 70)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   11,     6,    87,     8,     6,    19,     1,  2116,  5349,\n",
       "        8931,    15,    44,    30,   953,    72,  9375,    97,    22,\n",
       "          36,  8644,     3,    23, 12342,  1428,   812,    37,   225,\n",
       "          26,    81,   129,  2892,    87,     5,   506,   102,    10,\n",
       "          62,    25,  5862,    14,   159,   706,  1711,    98,    67,\n",
       "          25,    52,    15,     1,   100,    26,     5,    25,  4387,\n",
       "           3,    56,    24,   979,    11, 13373,     7,     9,    17,\n",
       "           5,   285,     8,     2,    55,    82,    17], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 70)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.hstack(([0], padded_sequences_test[0][:3], padded_sequences_test[0][4:]))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(generate(padded_sequences_test[:1]))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'models/lstm_word2vec' model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open(MODEL_NAME + '.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(MODEL_NAME + \".hdf5\")\n",
    "metrics=['accuracy', 'fmeasure', 'precision', 'recall']\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=metrics)\n",
    "print(\"Loaded '%s' model from disk\" % MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 70, 300)       6000000     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 256)           439296      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 256)           0           bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             257         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 6,439,553\n",
      "Trainable params: 439,553\n",
      "Non-trainable params: 6,000,000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding(text):\n",
    "    return pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lstm_predict(text):\n",
    "    return loaded_model.predict(padding(preprocess(text)))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65912354"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_predict(\"not bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91656721"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_predict(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(sequence):\n",
    "    rez = []\n",
    "    for i in range(len(sequence)):\n",
    "        rez.append(np.hstack(([0], padded_sequences_test[0][:i], padded_sequences_test[0][i+1:])))\n",
    "    return np.array(rez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(hacked):\n",
    "    return [p[0] for p in loaded_model.predict(hacked)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare(sequences, seq_preds):\n",
    "    word_scores = {}\n",
    "    for si, seq in enumerate(sequences):\n",
    "        \n",
    "        hacked = generate(seq) # 69x70\n",
    "        preds = predict(hacked)\n",
    "        \n",
    "        #70x1\n",
    "        for i, word in enumerate(seq):\n",
    "            \n",
    "            seq_score = seq_preds[si]\n",
    "            \n",
    "            if word not in word_scores:\n",
    "                word_scores[word] = []\n",
    "            \n",
    "            word_scores[word].append(seq_score - preds[i])\n",
    "    return word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_to_word = {index: word for word, index in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_scores = compare(padded_sequences_test, predict(padded_sequences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_values = []\n",
    "for word_index, scores in word_scores.items():\n",
    "    s = sorted(scores)\n",
    "    word_values.append({\n",
    "        'word': index_to_word.get(word_index, 'NAN'),\n",
    "        'min': s[0],\n",
    "        'max': s[-1],\n",
    "        'mean': np.mean(s),\n",
    "        'count': len(s),\n",
    "        'pos_count': len([s0 for s0 in s if s0 > 0]),\n",
    "        'neg_count': len([s0 for s0 in s if s0 < 0]),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rez = pd.DataFrame(word_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17629, 7)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1389</td>\n",
       "      <td>0.99489</td>\n",
       "      <td>0.165815</td>\n",
       "      <td>-0.839681</td>\n",
       "      <td>586</td>\n",
       "      <td>803</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count      max      mean       min  neg_count  pos_count word\n",
       "82  1389   0.99489  0.165815 -0.839681  586        803        bad"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez[rez['word'] == 'bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenya/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>neg_count</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>40</td>\n",
       "      <td>0.995934</td>\n",
       "      <td>0.942692</td>\n",
       "      <td>-0.005341</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>wonderfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>38</td>\n",
       "      <td>0.995151</td>\n",
       "      <td>0.929684</td>\n",
       "      <td>0.159606</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>delightful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>25</td>\n",
       "      <td>0.993663</td>\n",
       "      <td>0.907994</td>\n",
       "      <td>0.033720</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>refreshing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>20</td>\n",
       "      <td>0.994003</td>\n",
       "      <td>0.953459</td>\n",
       "      <td>0.651560</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>15</td>\n",
       "      <td>0.996041</td>\n",
       "      <td>0.906866</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>courage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>16</td>\n",
       "      <td>0.993790</td>\n",
       "      <td>0.910703</td>\n",
       "      <td>0.398391</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>mickey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>19</td>\n",
       "      <td>0.994245</td>\n",
       "      <td>0.925410</td>\n",
       "      <td>0.199421</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>musicals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>8</td>\n",
       "      <td>0.994207</td>\n",
       "      <td>0.985540</td>\n",
       "      <td>0.940957</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>riveting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>14</td>\n",
       "      <td>0.994041</td>\n",
       "      <td>0.960329</td>\n",
       "      <td>0.699155</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>superbly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>25</td>\n",
       "      <td>0.993456</td>\n",
       "      <td>0.918839</td>\n",
       "      <td>0.155415</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>13</td>\n",
       "      <td>0.994700</td>\n",
       "      <td>0.945108</td>\n",
       "      <td>0.553231</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>perfection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>9</td>\n",
       "      <td>0.994472</td>\n",
       "      <td>0.958136</td>\n",
       "      <td>0.700657</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>provocative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>8</td>\n",
       "      <td>0.993801</td>\n",
       "      <td>0.946427</td>\n",
       "      <td>0.772559</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>builds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>15</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.910734</td>\n",
       "      <td>0.159623</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>splendid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>7</td>\n",
       "      <td>0.994515</td>\n",
       "      <td>0.989814</td>\n",
       "      <td>0.979972</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>remarkably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>12</td>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.934761</td>\n",
       "      <td>0.723443</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>rachel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>15</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>0.977564</td>\n",
       "      <td>0.926269</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>flawless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>11</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>0.924443</td>\n",
       "      <td>0.755248</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>arguably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>17</td>\n",
       "      <td>0.996041</td>\n",
       "      <td>0.911884</td>\n",
       "      <td>-0.004594</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>tender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>18</td>\n",
       "      <td>0.993717</td>\n",
       "      <td>0.954382</td>\n",
       "      <td>0.718165</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>overlooked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>4</td>\n",
       "      <td>0.986830</td>\n",
       "      <td>0.959983</td>\n",
       "      <td>0.931406</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>astonishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>5</td>\n",
       "      <td>0.992171</td>\n",
       "      <td>0.937527</td>\n",
       "      <td>0.733175</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>worn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>12</td>\n",
       "      <td>0.993131</td>\n",
       "      <td>0.909876</td>\n",
       "      <td>0.519811</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>ward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>7</td>\n",
       "      <td>0.994205</td>\n",
       "      <td>0.908969</td>\n",
       "      <td>0.596901</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>pleasures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>10</td>\n",
       "      <td>0.994227</td>\n",
       "      <td>0.971900</td>\n",
       "      <td>0.849668</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>absorbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>13</td>\n",
       "      <td>0.994181</td>\n",
       "      <td>0.900913</td>\n",
       "      <td>0.057005</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>sublime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>22</td>\n",
       "      <td>0.994538</td>\n",
       "      <td>0.979575</td>\n",
       "      <td>0.919369</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>cried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>8</td>\n",
       "      <td>0.995344</td>\n",
       "      <td>0.911715</td>\n",
       "      <td>0.749122</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>metaphor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994234</td>\n",
       "      <td>0.949471</td>\n",
       "      <td>0.850252</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>corruption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>10</td>\n",
       "      <td>0.993309</td>\n",
       "      <td>0.904101</td>\n",
       "      <td>0.160112</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>simplicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14663</th>\n",
       "      <td>4</td>\n",
       "      <td>0.993217</td>\n",
       "      <td>0.972467</td>\n",
       "      <td>0.939420</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>buã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>4</td>\n",
       "      <td>0.992995</td>\n",
       "      <td>0.985824</td>\n",
       "      <td>0.965501</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>dripped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15043</th>\n",
       "      <td>6</td>\n",
       "      <td>0.993949</td>\n",
       "      <td>0.924189</td>\n",
       "      <td>0.768573</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>n64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>5</td>\n",
       "      <td>0.993221</td>\n",
       "      <td>0.992750</td>\n",
       "      <td>0.991578</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>blackadder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>4</td>\n",
       "      <td>0.989403</td>\n",
       "      <td>0.982201</td>\n",
       "      <td>0.965635</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>rpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15322</th>\n",
       "      <td>4</td>\n",
       "      <td>0.992417</td>\n",
       "      <td>0.987717</td>\n",
       "      <td>0.975843</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>flowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15436</th>\n",
       "      <td>4</td>\n",
       "      <td>0.993460</td>\n",
       "      <td>0.968251</td>\n",
       "      <td>0.939077</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>uel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15507</th>\n",
       "      <td>4</td>\n",
       "      <td>0.991544</td>\n",
       "      <td>0.903050</td>\n",
       "      <td>0.739479</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>valentino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15531</th>\n",
       "      <td>6</td>\n",
       "      <td>0.994154</td>\n",
       "      <td>0.969760</td>\n",
       "      <td>0.875578</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>curl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15534</th>\n",
       "      <td>5</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.926593</td>\n",
       "      <td>0.793648</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>sjã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15538</th>\n",
       "      <td>8</td>\n",
       "      <td>0.993456</td>\n",
       "      <td>0.913645</td>\n",
       "      <td>0.403714</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>bobbie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15543</th>\n",
       "      <td>5</td>\n",
       "      <td>0.993322</td>\n",
       "      <td>0.954982</td>\n",
       "      <td>0.916330</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>mani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15565</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994436</td>\n",
       "      <td>0.988129</td>\n",
       "      <td>0.983809</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>winkler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15654</th>\n",
       "      <td>5</td>\n",
       "      <td>0.992353</td>\n",
       "      <td>0.987343</td>\n",
       "      <td>0.984552</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>spanky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15693</th>\n",
       "      <td>4</td>\n",
       "      <td>0.992704</td>\n",
       "      <td>0.990679</td>\n",
       "      <td>0.989612</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>moto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15831</th>\n",
       "      <td>4</td>\n",
       "      <td>0.991703</td>\n",
       "      <td>0.968091</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>selections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15981</th>\n",
       "      <td>6</td>\n",
       "      <td>0.993139</td>\n",
       "      <td>0.969463</td>\n",
       "      <td>0.950586</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>currie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15983</th>\n",
       "      <td>8</td>\n",
       "      <td>0.991526</td>\n",
       "      <td>0.977583</td>\n",
       "      <td>0.953947</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>lull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16029</th>\n",
       "      <td>4</td>\n",
       "      <td>0.982147</td>\n",
       "      <td>0.907846</td>\n",
       "      <td>0.728306</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>evaluate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16062</th>\n",
       "      <td>4</td>\n",
       "      <td>0.990553</td>\n",
       "      <td>0.951791</td>\n",
       "      <td>0.862152</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>romantics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16141</th>\n",
       "      <td>4</td>\n",
       "      <td>0.993273</td>\n",
       "      <td>0.990263</td>\n",
       "      <td>0.988265</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>footprints</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16184</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994568</td>\n",
       "      <td>0.969229</td>\n",
       "      <td>0.943397</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>urich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16568</th>\n",
       "      <td>5</td>\n",
       "      <td>0.988291</td>\n",
       "      <td>0.926490</td>\n",
       "      <td>0.793414</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>strã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>4</td>\n",
       "      <td>0.993757</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.940664</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>rockin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>5</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.990378</td>\n",
       "      <td>0.985097</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>erasmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17029</th>\n",
       "      <td>4</td>\n",
       "      <td>0.993713</td>\n",
       "      <td>0.939825</td>\n",
       "      <td>0.784893</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>mahoney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17088</th>\n",
       "      <td>4</td>\n",
       "      <td>0.977627</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.963876</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>patekar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17236</th>\n",
       "      <td>4</td>\n",
       "      <td>0.979427</td>\n",
       "      <td>0.961918</td>\n",
       "      <td>0.930462</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>heartache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>5</td>\n",
       "      <td>0.993831</td>\n",
       "      <td>0.977590</td>\n",
       "      <td>0.954641</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>breathed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17519</th>\n",
       "      <td>5</td>\n",
       "      <td>0.987547</td>\n",
       "      <td>0.951265</td>\n",
       "      <td>0.850262</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>desdemona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       max      mean       min  neg_count  pos_count         word\n",
       "1565   40     0.995934  0.942692 -0.005341  1          39         wonderfully\n",
       "1697   38     0.995151  0.929684  0.159606  0          38         delightful \n",
       "2266   25     0.993663  0.907994  0.033720  0          25         refreshing \n",
       "2315   20     0.994003  0.953459  0.651560  0          20         ensemble   \n",
       "2864   15     0.996041  0.906866  0.407500  0          15         courage    \n",
       "2937   16     0.993790  0.910703  0.398391  0          16         mickey     \n",
       "3005   19     0.994245  0.925410  0.199421  0          19         musicals   \n",
       "3023   8      0.994207  0.985540  0.940957  0          8          riveting   \n",
       "3059   14     0.994041  0.960329  0.699155  0          14         superbly   \n",
       "3069   25     0.993456  0.918839  0.155415  0          25         daily      \n",
       "3215   13     0.994700  0.945108  0.553231  0          13         perfection \n",
       "3230   9      0.994472  0.958136  0.700657  0          9          provocative\n",
       "3359   8      0.993801  0.946427  0.772559  0          8          builds     \n",
       "3427   15     0.994755  0.910734  0.159623  0          15         splendid   \n",
       "3445   7      0.994515  0.989814  0.979972  0          7          remarkably \n",
       "3534   12     0.994119  0.934761  0.723443  0          12         rachel     \n",
       "3548   15     0.994697  0.977564  0.926269  0          15         flawless   \n",
       "3567   11     0.994566  0.924443  0.755248  0          11         arguably   \n",
       "3586   17     0.996041  0.911884 -0.004594  1          16         tender     \n",
       "3648   18     0.993717  0.954382  0.718165  0          18         overlooked \n",
       "3800   4      0.986830  0.959983  0.931406  0          4          astonishing\n",
       "3918   5      0.992171  0.937527  0.733175  0          5          worn       \n",
       "3947   12     0.993131  0.909876  0.519811  0          12         ward       \n",
       "3968   7      0.994205  0.908969  0.596901  0          7          pleasures  \n",
       "4058   10     0.994227  0.971900  0.849668  0          10         absorbing  \n",
       "4117   13     0.994181  0.900913  0.057005  0          13         sublime    \n",
       "4118   22     0.994538  0.979575  0.919369  0          22         cried      \n",
       "4220   8      0.995344  0.911715  0.749122  0          8          metaphor   \n",
       "4251   4      0.994234  0.949471  0.850252  0          4          corruption \n",
       "4281   10     0.993309  0.904101  0.160112  0          10         simplicity \n",
       "...    ..          ...       ...       ... ..          ..                ... \n",
       "14663  4      0.993217  0.972467  0.939420  0          4          buã        \n",
       "14798  4      0.992995  0.985824  0.965501  0          4          dripped    \n",
       "15043  6      0.993949  0.924189  0.768573  0          6          n64        \n",
       "15307  5      0.993221  0.992750  0.991578  0          5          blackadder \n",
       "15317  4      0.989403  0.982201  0.965635  0          4          rpg        \n",
       "15322  4      0.992417  0.987717  0.975843  0          4          flowed     \n",
       "15436  4      0.993460  0.968251  0.939077  0          4          uel        \n",
       "15507  4      0.991544  0.903050  0.739479  0          4          valentino  \n",
       "15531  6      0.994154  0.969760  0.875578  0          6          curl       \n",
       "15534  5      0.988235  0.926593  0.793648  0          5          sjã        \n",
       "15538  8      0.993456  0.913645  0.403714  0          8          bobbie     \n",
       "15543  5      0.993322  0.954982  0.916330  0          5          mani       \n",
       "15565  4      0.994436  0.988129  0.983809  0          4          winkler    \n",
       "15654  5      0.992353  0.987343  0.984552  0          5          spanky     \n",
       "15693  4      0.992704  0.990679  0.989612  0          4          moto       \n",
       "15831  4      0.991703  0.968091  0.943349  0          4          selections \n",
       "15981  6      0.993139  0.969463  0.950586  0          6          currie     \n",
       "15983  8      0.991526  0.977583  0.953947  0          8          lull       \n",
       "16029  4      0.982147  0.907846  0.728306  0          4          evaluate   \n",
       "16062  4      0.990553  0.951791  0.862152  0          4          romantics  \n",
       "16141  4      0.993273  0.990263  0.988265  0          4          footprints \n",
       "16184  4      0.994568  0.969229  0.943397  0          4          urich      \n",
       "16568  5      0.988291  0.926490  0.793414  0          5          strã       \n",
       "16595  4      0.993757  0.974874  0.940664  0          4          rockin     \n",
       "16796  5      0.994203  0.990378  0.985097  0          5          erasmus    \n",
       "17029  4      0.993713  0.939825  0.784893  0          4          mahoney    \n",
       "17088  4      0.977627  0.972439  0.963876  0          4          patekar    \n",
       "17236  4      0.979427  0.961918  0.930462  0          4          heartache  \n",
       "17496  5      0.993831  0.977590  0.954641  0          5          breathed   \n",
       "17519  5      0.987547  0.951265  0.850262  0          5          desdemona  \n",
       "\n",
       "[347 rows x 7 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez[rez['mean'] > 0.9][rez['pos_count'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
